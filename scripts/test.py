from pyspark.sql import SparkSession

# 1. CrÃ©er une session Spark
spark = SparkSession.builder \
    .appName("AccidentsAnalyse") \
    .getOrCreate()

# 2. Charger le dataset
df = spark.read.csv("../dataset/US_Accidents.csv", header=True, inferSchema=True)

# 3. âœ… VÃ©rifier que le dataset est bien chargÃ©
print("âœ… Dataset chargÃ© avec succÃ¨s")
df.show(5)              # ğŸ‘‰ Affiche les 5 premiÃ¨res lignes
df.printSchema()        # ğŸ‘‰ Affiche le type des colonnes
print("Nombre de lignes :", df.count())  # ğŸ‘‰ Nombre total de lignes
print("Colonnes :", df.columns)          # ğŸ‘‰ Liste des colonnes

# 4. Fermer proprement Spark
spark.stop()
